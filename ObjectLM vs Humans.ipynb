{
 "metadata": {
  "name": "",
  "signature": "sha256:e6d0aa867f02b0b9698a87f7dffbefdfe8aa558e41ee9561a94f52b4e96fab29"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%matplotlib inline\n",
      "%autoreload 2\n",
      "%config InlineBackend.figure_format = 'png'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# ObjectLM vs Humans\n",
      "\n",
      "To compare our recommender system to human responses we look at the agreement between the two responses.\n",
      "\n",
      "First we load the covariance matrix and the observations from Mechanical Turk:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from boto.mturk.connection import MTurkConnection\n",
      "import os, numpy as np, matplotlib.pyplot as plt\n",
      "from objectlm import HierarchicalObservation\n",
      "from personality import load_example_sets, collect_hit_responses\n",
      "\n",
      "mtc = MTurkConnection(aws_access_key_id=os.environ['AWS_PENG_ID'],\n",
      "                      aws_secret_access_key=os.environ['AWS_PENG_SECRET'],\n",
      "                      host=\"mechanicalturk.amazonaws.com\")\n",
      "mtc_b = MTurkConnection(aws_access_key_id=os.environ['AWS_ID'],\n",
      "                      aws_secret_access_key=os.environ['AWS_SECRET'],\n",
      "                      host=\"mechanicalturk.amazonaws.com\")\n",
      "# model covariance:\n",
      "Cov = np.load(\"saves/bilinear/__covariance__.npy\")\n",
      "observables = HierarchicalObservation(Cov)\n",
      "# Mechanical Turk data:\n",
      "loaded_example_sets = load_example_sets(\"saves/example_sets.pkz\")\n",
      "responses_to_example_sets = [[resp for resp in example.get_responses([mtc, mtc_b]) if resp['RejectionTime'] == None and resp['ApprovalTime'] != None] for example in loaded_example_sets]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can then compare the responses from both models:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using bilinear ObjectLM's covariance matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "document2index = get_doc2index()\n",
      "model_responses = np.array([model_response(document2index, ex) for ex in loaded_example_sets])\n",
      "human_common_responses = np.array([resp_to_common_index(document2index,loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])\n",
      "personalities = np.array([ex.personality_type for ex in loaded_example_sets])\n",
      "agreement = np.array([agreement(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "agreement_distance = np.array([distance_to_next_most_popular(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "\n",
      "lines, latex_lines = compare_model_responses(document2index, model_responses, responses_to_example_sets, loaded_example_sets, personalities)\n",
      "show_table(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>43.52%</td><td>25.00%</td><td>44.44%</td><td>58.33%</td><td>41.67%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>62.96%</td><td>66.67%</td><td>61.11%</td><td>66.67%</td><td>66.67%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>80.56%</td><td>91.67%</td><td>79.17%</td><td>75.00%</td><td>83.33%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x189aadba8>"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using linear ObjectLM's covariance matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_responses = np.array([model_response(document2index, ex) for ex in loaded_example_sets])\n",
      "human_common_responses = np.array([resp_to_common_index(document2index,loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])\n",
      "personalities = np.array([ex.personality_type for ex in loaded_example_sets])\n",
      "agreement = np.array([agreement(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "agreement_distance = np.array([distance_to_next_most_popular(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "\n",
      "lines, latex_lines = compare_model_responses(document2index, model_responses, responses_to_example_sets, loaded_example_sets, personalities)\n",
      "show_table(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>40.74%</td><td>33.33%</td><td>43.06%</td><td>25.00%</td><td>50.00%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>62.96%</td><td>75.00%</td><td>61.11%</td><td>50.00%</td><td>75.00%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>81.48%</td><td>100.00%</td><td>80.56%</td><td>58.33%</td><td>91.67%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x164fc4588>"
       ]
      }
     ],
     "prompt_number": 398
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fix scraping errors, and define some simple calculations over our data to get the results:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyxdameraulevenshtein import damerau_levenshtein_distance as levenshtein_distance\n",
      "from operator import itemgetter\n",
      "from utils import get_database\n",
      "from numpy.linalg import LinAlgError\n",
      "from collections import Counter\n",
      "import gzip, pickle, re\n",
      "\n",
      "def get_doc2index():\n",
      "    file = gzip.open(\"saves/saved_texts.gz\", 'r')\n",
      "    texts, texts_data = pickle.load(file)\n",
      "    file.close()\n",
      "    document2index = {}\n",
      "    cat_rating_price_2index = {}\n",
      "    for k, text in enumerate(texts_data):\n",
      "        given_name = get_database()[\"restaurants\"].find_one({\"_id\": text[\"_id\"]}, {\"given_name\": 1}).get(\"given_name\")\n",
      "        document2index[text[\"_id\"]] = k\n",
      "        document2index[text[\"id\"]] = k\n",
      "        if given_name != None:\n",
      "            document2index[given_name] = k\n",
      "        if cat_rating_price_2index.get((int(text[\"rating\"]), len(text[\"price\"]), \",\".join(text[\"categories\"]))) is None:\n",
      "            cat_rating_price_2index[(int(text[\"rating\"]), len(text[\"price\"]), \",\".join(text[\"categories\"]))] = [k]\n",
      "        else:\n",
      "            cat_rating_price_2index[(int(text[\"rating\"]), len(text[\"price\"]), \",\".join(text[\"categories\"]))].append(k)\n",
      "\n",
      "    # fixes:\n",
      "    document2index[\"The Georgian Restaurant\"] = 4697\n",
      "    document2index[\"Papa Murphy's Take 'N' Bake pizza\"] = 307\n",
      "    document2index[\"The Hi-life\"] = 1774\n",
      "    document2index[\"Popeyes Louisiana Kitchen\"] = 2144\n",
      "    document2index[\"TASTE Restaurant\"] = 5813\n",
      "    document2index[\"Ballet Vietnamese Restaurant\"] = 4845\n",
      "    document2index[\"Dot's Charcuterie and Bistrot\"] = 3539\n",
      "    document2index[\"Shuckers Oyster Bar\"] = 2985\n",
      "    document2index[\"Jersey Mike's Subs\"] = 2399\n",
      "    document2index[\"Elysian Tangletown\"] = 3910\n",
      "    document2index[\"Buca di Beppo Italian Restaurant\"] = 5877\n",
      "    document2index[\"Ugly Mug Caf\u00e9 & Coffee Roasters\"] = 4365\n",
      "    document2index[\"Salty's\"] = 2173\n",
      "    document2index[\"Ti22\"] = 5732\n",
      "\n",
      "    rating_finder = re.compile(\"<span class='rating'>([^<]+)</span>\")\n",
      "    price_finder = re.compile(\"<span class='pricing'>([^<]*)</span>\")\n",
      "    category_finder = re.compile(\"<span class='category'>([^<]+)</span>\")\n",
      "\n",
      "    def get_rating(html):\n",
      "        return len(re.findall(rating_finder, html)[0])\n",
      "\n",
      "    def get_price(html):\n",
      "        return len(re.findall(price_finder, html)[0])\n",
      "\n",
      "    def get_categories(html):\n",
      "        return \",\".join(re.findall(category_finder, html))\n",
      "    \n",
      "    ambiguous = set()\n",
      "    for ex in loaded_example_sets:\n",
      "        for k, name in enumerate(ex.example_names()):\n",
      "            if not name.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\") in document2index:\n",
      "                html = ex.get_examples_html()[k]\n",
      "                rating = get_rating(html)\n",
      "                price = get_price(html)\n",
      "                categories = get_categories(html)\n",
      "                if len(cat_rating_price_2index[(rating, price, categories)]) > 1:\n",
      "                    alternates =[(texts_data[i][\"_id\"].replace(\"-\", \" \"), i) for i in cat_rating_price_2index[(rating, price, categories)]]\n",
      "\n",
      "                    found = False\n",
      "                    for alternate,i in alternates:\n",
      "                        if alternate.lower().find(name.lower()) != -1:\n",
      "                            document2index[name] = i\n",
      "                            found = True\n",
      "\n",
      "                    if not found:\n",
      "                        distances = [(levenshtein_distance(name.lower(), alternate.lower()), alternate, i) for alternate, i in alternates]\n",
      "                        distances.sort(key=itemgetter(0))\n",
      "                        if distances[0][0] < 3:\n",
      "                            document2index[name] = distances[0][2]\n",
      "                        else:\n",
      "                            ambiguous.add(name)\n",
      "                            print(name, distances)\n",
      "                else:\n",
      "                    document2index[name] = cat_rating_price_2index[(rating, price, categories)][0]\n",
      "\n",
      "        for k, name in enumerate(ex.option_names()):\n",
      "            if not name.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\") in document2index:\n",
      "                html = ex.get_options_html()[k]\n",
      "                rating = get_rating(html)\n",
      "                price = get_price(html)\n",
      "                categories = get_categories(html)\n",
      "                if len(cat_rating_price_2index[(rating, price, categories)]) > 1:\n",
      "                    alternates =[(texts_data[i][\"_id\"].replace(\"-\", \" \"), i) for i in cat_rating_price_2index[(rating, price, categories)]]\n",
      "\n",
      "                    found = False\n",
      "                    for alternate,i in alternates:\n",
      "                        if alternate.lower().find(name.lower()) != -1:\n",
      "                            document2index[name] = i\n",
      "                            found = True\n",
      "\n",
      "                    if not found:\n",
      "                        distances = [(levenshtein_distance(name.lower(), alternate.lower()), alternate, i) for alternate, i in alternates]\n",
      "                        distances.sort(key=itemgetter(0))\n",
      "                        if distances[0][0] < 5:\n",
      "                            document2index[name] = distances[0][2]\n",
      "                        else:\n",
      "                            ambiguous.add(name)\n",
      "                            if distances[0][0] > len(name):\n",
      "                                print(name, distances)\n",
      "                else:\n",
      "                    document2index[name] = cat_rating_price_2index[(rating, price, categories)][0]\n",
      "    return document2index\n",
      "\n",
      "def convert_names_to_indices(document2index, names):\n",
      "    return [document2index.get(name.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\"), document2index.get(name.lower(), None)) for name in names]\n",
      "\n",
      "def model_response(document2index, example):\n",
      "    indices = convert_names_to_indices(document2index, example.example_names())\n",
      "    test_indices = convert_names_to_indices(document2index, example.option_names())\n",
      "    intersect = set(indices) & set(test_indices)\n",
      "    if len(intersect) == 0:\n",
      "        try:\n",
      "            result_inds, result_probs = observables.conditional_probabilities(indices, remaining_indices = test_indices)\n",
      "            return test_indices[result_probs[:,0].argmax()]\n",
      "        except LinAlgError:\n",
      "            result_inds, result_probs = observables.conditional_probabilities(indices, remaining_indices = test_indices, singular=True)\n",
      "            return test_indices[result_probs[:,0].argmax()]\n",
      "    else:\n",
      "        return intersect\n",
      "\n",
      "def resp_to_common_index(document2index, ex, response, index):\n",
      "    \n",
      "    if index < 4:\n",
      "        common_name = Counter(resp[\"recommendation\"].split(\" \")[0] for resp in response).most_common(2)\n",
      "    else:\n",
      "        common_name = Counter(resp[\"recommendation\"] for resp in response).most_common(2)\n",
      "    \n",
      "    if index < 4:\n",
      "        actual_names = [name.split(\" \")[0] for name in ex.option_names()]\n",
      "        actual_index = actual_names.index(common_name[0][0])\n",
      "        common_name = ex.option_names()[actual_index]\n",
      "    else:\n",
      "        common_name = common_name[0][0]\n",
      "    \n",
      "    return document2index.get(common_name.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\"), document2index.get(common_name.lower(), None))\n",
      "\n",
      "def agreement(response, index):\n",
      "    recommendations = Counter(result[\"recommendation\"] for result in response)\n",
      "    \n",
      "    if index < 4:\n",
      "        recommendations = Counter(result[\"recommendation\"].split(\" \")[0] for result in response)\n",
      "    \n",
      "    num_responses = sum(reco[1] for reco in recommendations.most_common())\n",
      "    return recommendations.most_common(1)[0][1]\n",
      "\n",
      "def agrees_with_human(document2index, model_response, ex, response, index, cutoff):\n",
      "    if index < 4:\n",
      "        recommendations = Counter(result[\"recommendation\"].split(\" \")[0] for result in response)\n",
      "        actual_names = [name.split(\" \")[0] for name in ex.option_names()]\n",
      "        for fake_key, count in recommendations.most_common():\n",
      "            actual_index = actual_names.index(fake_key)\n",
      "            key = ex.option_names()[actual_index]\n",
      "            if count < cutoff:\n",
      "                return 0\n",
      "            key_index = document2index.get(key.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\"), document2index.get(key.lower(), None))\n",
      "            if model_response == key_index:\n",
      "                return 1\n",
      "        return 0\n",
      "        \n",
      "    else:\n",
      "        recommendations = Counter(result[\"recommendation\"] for result in response)\n",
      "        for key, count in recommendations.most_common():\n",
      "            if count < cutoff:\n",
      "                return 0\n",
      "            key_index = document2index.get(key.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\"), document2index.get(key.lower(), None))\n",
      "            if model_response == key_index:\n",
      "                return 1\n",
      "            \n",
      "        return 0\n",
      "    \n",
      "\n",
      "def distance_to_next_most_popular(response, index):\n",
      "    recommendations = Counter(result[\"recommendation\"] for result in response)\n",
      "    \n",
      "    if index < 4:\n",
      "        recommendations = Counter(result[\"recommendation\"].split(\" \")[0] for result in response)\n",
      "    \n",
      "    if len(recommendations) > 1:\n",
      "        return recommendations.most_common(2)[0][1] - recommendations.most_common(2)[1][1]\n",
      "    else:\n",
      "        return recommendations.most_common(1)[0][1]\n",
      "def compare_model_responses(document2index, system_responses, human_responses, example_sets, personalities):\n",
      "    agrees_with_many_humans = np.array([agrees_with_human(document2index, model_resp,example_sets[k],human_responses[k],k,3) for k, model_resp in enumerate(system_responses)])\n",
      "    agrees_with_some_humans = np.array([agrees_with_human(document2index, model_resp,example_sets[k],human_responses[k],k,2) for k, model_resp in enumerate(system_responses)])\n",
      "    agrees_with_a_humans    = np.array([agrees_with_human(document2index, model_resp,example_sets[k],human_responses[k],k,1) for k, model_resp in enumerate(system_responses)])\n",
      "\n",
      "    results = []\n",
      "\n",
      "    result_row = [\n",
      "        100 * agrees_with_many_humans.sum() / len(agrees_with_many_humans),\n",
      "        100 * agrees_with_some_humans.sum() / len(agrees_with_some_humans),\n",
      "        100 * agrees_with_a_humans.sum()    / len(agrees_with_a_humans)\n",
      "    ]\n",
      "\n",
      "    results.append(result_row)\n",
      "\n",
      "\n",
      "    for i, p_type in enumerate([\"Price\", \"Cuisine\", \"Rating\", \"Value\"]):\n",
      "        matches = np.where(personalities == i)[0]\n",
      "        result_row = [\n",
      "        100 * agrees_with_many_humans[matches].sum() / len(matches),\n",
      "        100 * agrees_with_some_humans[matches].sum() / len(matches),\n",
      "        100 * agrees_with_a_humans[matches].sum()    / len(matches)\n",
      "                    ]\n",
      "        results.append(result_row)\n",
      "\n",
      "    agreement_types = [\">2 subjects\", \">1 subjects\", \">0 subjects\"]\n",
      "\n",
      "    lines = []\n",
      "    latex_lines = []\n",
      "\n",
      "    latex_lines.append(\" & \".join([\"\\# agree w/. model\", \"Overall\", \"Price\", \"Cuisine\", \"Rating\", \"Value\"]) + \" \\\\\\\\\")\n",
      "    lines.append([\"# agree w/. model\", \"Overall\", \"Price\", \"Cuisine\", \"Rating\", \"Value\"])\n",
      "    latex_lines.append(\"\\hline\")\n",
      "    for k, agreement_type in enumerate(agreement_types):\n",
      "        line = [\"%s \" % (agreement_type)]\n",
      "        line += [\"%.1f\\%%\"% (results[j][k]) for j in range(len(results))]\n",
      "        latex_lines.append(\" & \".join(line) +  \" \\\\\\\\\")\n",
      "        line = [\"%s \" % (agreement_type)] + [\"%.2f%%\"% (results[j][k]) for j in range(len(results))]\n",
      "        lines.append(line)\n",
      "        \n",
      "    return (lines, latex_lines)\n",
      "from IPython.display import display, HTML\n",
      "def show_table(lines):\n",
      "    display(\n",
      "        HTML(\n",
      "            \"\"\"<div class='row'>\n",
      "                    <div class='span7'>\n",
      "                        <table class='table table-bordered'>\n",
      "                            <tbody>\n",
      "                                <tr>\n",
      "                                    <th>\"\"\" + \\\n",
      "                                    \"</th><th>\".join(lines[0]) + \"</th></tr>\" + \\\n",
      "                                    \"</tr>\\n<tr>\".join(\n",
      "                                        [\"<td>\" + \"</td><td>\".join(line) + \"</td>\" for line in lines[1:]]\n",
      "                                    ) + \"\"\"\n",
      "                                </tr>\n",
      "                            </tbody>\n",
      "                        </table>\n",
      "                    </div>\n",
      "                </div>\"\"\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}