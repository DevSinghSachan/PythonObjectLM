{
 "metadata": {
  "name": "",
  "signature": "sha256:c738a79c0776d157821d16911b6507df3bde65239c8e057faf387a8c2ba75cb2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%matplotlib inline\n",
      "%autoreload 2\n",
      "%config InlineBackend.figure_format = 'png'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# ObjectLM vs Humans\n",
      "\n",
      "To compare our recommender system to human responses we look at the agreement between the two responses.\n",
      "\n",
      "First we load the covariance matrix and the observations from Mechanical Turk:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from boto.mturk.connection import MTurkConnection\n",
      "import os, numpy as np, matplotlib.pyplot as plt\n",
      "from objectlm import HierarchicalObservation\n",
      "from personality import load_example_sets, collect_hit_responses\n",
      "from utils.covariance import tfidf_covariance, objectlm_covariance\n",
      "\n",
      "mtc = MTurkConnection(aws_access_key_id=os.environ['AWS_PENG_ID'],\n",
      "                      aws_secret_access_key=os.environ['AWS_PENG_SECRET'],\n",
      "                      host=\"mechanicalturk.amazonaws.com\")\n",
      "mtc_b = MTurkConnection(aws_access_key_id=os.environ['AWS_ID'],\n",
      "                      aws_secret_access_key=os.environ['AWS_SECRET'],\n",
      "                      host=\"mechanicalturk.amazonaws.com\")\n",
      "\n",
      "\n",
      "# model covariance:\n",
      "observables = tfidf_covariance(None, \"saves/tfidf\")\n",
      "observables_bilinear = objectlm_covariance(\n",
      "            None,\n",
      "            \"saves/bilinear\")\n",
      "observables_objectlm = objectlm_covariance(\n",
      "            None,\n",
      "            \"saves/linear\")\n",
      "observables_svm = objectlm_covariance(\n",
      "    None, \"saves/svm\", metric=\"euclidean\")\n",
      "observables_pLSA = objectlm_covariance(\n",
      "    None, \"saves/pLSA\", metric=\"cosine\")\n",
      "observables_pvdm = objectlm_covariance(\n",
      "    None, \"saves/pvdm/\", metric=\"cosine\")\n",
      "#Mechanical Turk data:\n",
      "loaded_example_sets = load_example_sets(\"saves/example_sets.pkz\")\n",
      "responses_to_example_sets = [[resp for resp in example.get_responses([mtc, mtc_b]) if resp['RejectionTime'] == None and resp['ApprovalTime'] != None] for example in loaded_example_sets]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def collect_simple_response(*args):\n",
      "    model_responses = np.array([model_response(document2index, ex, *args) for ex in loaded_example_sets])\n",
      "    human_common_responses = np.array([resp_to_common_index(document2index,loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])\n",
      "    personalities = np.array([ex.personality_type for ex in loaded_example_sets])\n",
      "    agreement_distance = np.array([distance_to_next_most_popular(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "\n",
      "    lines, latex_lines = compare_model_responses(document2index, model_responses, responses_to_example_sets, loaded_example_sets, personalities)\n",
      "    show_table(lines)\n",
      "    \n",
      "def collect_double_response(*args):\n",
      "    model_responses = np.array([double_model_response(document2index, ex, *args) for ex in loaded_example_sets])\n",
      "    human_common_responses = np.array([resp_to_common_index(document2index,loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])\n",
      "    personalities = np.array([ex.personality_type for ex in loaded_example_sets])\n",
      "    agreement_distance = np.array([distance_to_next_most_popular(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "\n",
      "    lines, latex_lines = compare_model_responses(document2index, model_responses, responses_to_example_sets, loaded_example_sets, personalities)\n",
      "    show_table(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can then compare the responses from both models:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using a rule based approach:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(human_common_amount == 2).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "15"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "human_common_amount = np.array([most_common_amount(document2index,loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#document2index = get_doc2index()\n",
      "model_responses = np.array([rule_response(document2index, ex) for ex in loaded_example_sets])\n",
      "human_common_responses = np.array([resp_to_common_index(document2index,loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])\n",
      "personalities = np.array([ex.personality_type for ex in loaded_example_sets])\n",
      "agreement = np.array([agreement(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "agreement_distance = np.array([distance_to_next_most_popular(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "\n",
      "lines, latex_lines = compare_model_responses(document2index, model_responses, responses_to_example_sets, loaded_example_sets, personalities)\n",
      "show_table(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>37.96%</td><td>25.00%</td><td>33.33%</td><td>75.00%</td><td>41.67%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>58.33%</td><td>58.33%</td><td>51.39%</td><td>83.33%</td><td>75.00%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>81.48%</td><td>83.33%</td><td>77.78%</td><td>100.00%</td><td>83.33%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x181c0f0b8>"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "document2index = get_doc2index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#document2index = get_doc2index()\n",
      "model_responses = np.array([rule_response_value(document2index, ex) for ex in loaded_example_sets])\n",
      "human_common_responses = np.array([resp_to_common_index(document2index,loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])\n",
      "personalities = np.array([ex.personality_type for ex in loaded_example_sets])\n",
      "agreement = np.array([agreement(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "agreement_distance = np.array([distance_to_next_most_popular(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "\n",
      "lines, latex_lines = compare_model_responses(document2index, model_responses, responses_to_example_sets, loaded_example_sets, personalities)\n",
      "show_table(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>51.85%</td><td>50.00%</td><td>48.61%</td><td>75.00%</td><td>50.00%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>68.52%</td><td>75.00%</td><td>63.89%</td><td>83.33%</td><td>75.00%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>90.74%</td><td>91.67%</td><td>90.28%</td><td>91.67%</td><td>91.67%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x181c1cba8>"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#document2index = get_doc2index()\n",
      "model_responses = np.array([rule_response_flavor(document2index, ex) for ex in loaded_example_sets])\n",
      "human_common_responses = np.array([resp_to_common_index(document2index,loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])\n",
      "personalities = np.array([ex.personality_type for ex in loaded_example_sets])\n",
      "agreement = np.array([agreement(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "agreement_distance = np.array([distance_to_next_most_popular(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "\n",
      "lines, latex_lines = compare_model_responses(document2index, model_responses, responses_to_example_sets, loaded_example_sets, personalities)\n",
      "show_table(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>28.70%</td><td>33.33%</td><td>30.56%</td><td>16.67%</td><td>25.00%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>51.85%</td><td>75.00%</td><td>51.39%</td><td>33.33%</td><td>50.00%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>72.22%</td><td>91.67%</td><td>72.22%</td><td>50.00%</td><td>75.00%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x181df8a20>"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Averaged bilinear and linear models:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collect_double_response(observables_bilinear, observables_objectlm, 10, 1, False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>43.52%</td><td>50.00%</td><td>44.44%</td><td>33.33%</td><td>41.67%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>64.81%</td><td>83.33%</td><td>62.50%</td><td>58.33%</td><td>66.67%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>82.41%</td><td>100.00%</td><td>81.94%</td><td>58.33%</td><td>91.67%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x13e06ec88>"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using bilinear ObjectLM's covariance matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collect_double_response(observables_bilinear, observables_objectlm, 10, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>41.67%</td><td>25.00%</td><td>44.44%</td><td>41.67%</td><td>41.67%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>62.04%</td><td>66.67%</td><td>61.11%</td><td>58.33%</td><td>66.67%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>80.56%</td><td>91.67%</td><td>79.17%</td><td>66.67%</td><td>91.67%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x13e06a1d0>"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using Paragraph Vector Distributed Memory (CBOW), window size 8, size = 300"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collect_simple_response(observables_pvdm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>36.11%</td><td>16.67%</td><td>38.89%</td><td>25.00%</td><td>50.00%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>53.70%</td><td>50.00%</td><td>51.39%</td><td>50.00%</td><td>75.00%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>75.00%</td><td>83.33%</td><td>72.22%</td><td>58.33%</td><td>100.00%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x113f808d0>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collect_simple_response(observables_svm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>25.00%</td><td>25.00%</td><td>26.39%</td><td>8.33%</td><td>33.33%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>46.30%</td><td>33.33%</td><td>48.61%</td><td>41.67%</td><td>50.00%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>74.07%</td><td>66.67%</td><td>76.39%</td><td>58.33%</td><td>83.33%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x13e06eda0>"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collect_simple_response(observables_pLSA)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>31.48%</td><td>41.67%</td><td>33.33%</td><td>33.33%</td><td>8.33%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>51.85%</td><td>58.33%</td><td>52.78%</td><td>58.33%</td><td>33.33%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>73.15%</td><td>75.00%</td><td>76.39%</td><td>58.33%</td><td>66.67%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x1bed17e80>"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collect_simple_response(observables)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>33.33%</td><td>41.67%</td><td>31.94%</td><td>25.00%</td><td>41.67%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>53.70%</td><td>50.00%</td><td>48.61%</td><td>66.67%</td><td>75.00%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>77.78%</td><td>75.00%</td><td>76.39%</td><td>66.67%</td><td>100.00%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x13e0bac18>"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collect_simple_response(observables_bilinear)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>43.52%</td><td>25.00%</td><td>44.44%</td><td>58.33%</td><td>41.67%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>62.96%</td><td>66.67%</td><td>61.11%</td><td>66.67%</td><td>66.67%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>80.56%</td><td>91.67%</td><td>79.17%</td><td>75.00%</td><td>83.33%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x13e0bac18>"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collect_simple_response(observables_objectlm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>40.74%</td><td>33.33%</td><td>43.06%</td><td>25.00%</td><td>50.00%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>62.96%</td><td>75.00%</td><td>61.11%</td><td>50.00%</td><td>75.00%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>81.48%</td><td>100.00%</td><td>80.56%</td><td>58.33%</td><td>91.67%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x13e06a0b8>"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_responses = np.array([double_model_response(document2index, ex) for ex in loaded_example_sets])\n",
      "human_common_responses = np.array([resp_to_common_index(document2index,loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])\n",
      "personalities = np.array([ex.personality_type for ex in loaded_example_sets])\n",
      "agreement = np.array([agreement(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "agreement_distance = np.array([distance_to_next_most_popular(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "\n",
      "lines, latex_lines = compare_model_responses(document2index, model_responses, responses_to_example_sets, loaded_example_sets, personalities)\n",
      "show_table(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>41.67%</td><td>41.67%</td><td>43.06%</td><td>33.33%</td><td>41.67%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>62.96%</td><td>83.33%</td><td>59.72%</td><td>58.33%</td><td>66.67%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>81.48%</td><td>100.00%</td><td>79.17%</td><td>66.67%</td><td>91.67%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x123283278>"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "document2index = get_doc2index()\n",
      "model_responses = np.array([model_response(document2index, ex) for ex in loaded_example_sets])\n",
      "human_common_responses = np.array([resp_to_common_index(document2index,loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])\n",
      "personalities = np.array([ex.personality_type for ex in loaded_example_sets])\n",
      "agreement = np.array([agreement(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "agreement_distance = np.array([distance_to_next_most_popular(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "\n",
      "lines, latex_lines = compare_model_responses(document2index, model_responses, responses_to_example_sets, loaded_example_sets, personalities)\n",
      "show_table(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>43.52%</td><td>25.00%</td><td>44.44%</td><td>58.33%</td><td>41.67%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>62.96%</td><td>66.67%</td><td>61.11%</td><td>66.67%</td><td>66.67%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>80.56%</td><td>91.67%</td><td>79.17%</td><td>75.00%</td><td>83.33%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x189aadba8>"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using linear ObjectLM's covariance matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_responses = np.array([model_response(document2index, ex) for ex in loaded_example_sets])\n",
      "human_common_responses = np.array([resp_to_common_index(document2index,loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])\n",
      "personalities = np.array([ex.personality_type for ex in loaded_example_sets])\n",
      "agreement = np.array([agreement(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "agreement_distance = np.array([distance_to_next_most_popular(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "\n",
      "lines, latex_lines = compare_model_responses(document2index, model_responses, responses_to_example_sets, loaded_example_sets, personalities)\n",
      "show_table(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div class='row'>\n",
        "                    <div class='span7'>\n",
        "                        <table class='table table-bordered'>\n",
        "                            <tbody>\n",
        "                                <tr>\n",
        "                                    <th># agree w/. model</th><th>Overall</th><th>Price</th><th>Cuisine</th><th>Rating</th><th>Value</th></tr><td>>2 subjects </td><td>40.74%</td><td>33.33%</td><td>43.06%</td><td>25.00%</td><td>50.00%</td></tr>\n",
        "<tr><td>>1 subjects </td><td>62.96%</td><td>75.00%</td><td>61.11%</td><td>50.00%</td><td>75.00%</td></tr>\n",
        "<tr><td>>0 subjects </td><td>81.48%</td><td>100.00%</td><td>80.56%</td><td>58.33%</td><td>91.67%</td>\n",
        "                                </tr>\n",
        "                            </tbody>\n",
        "                        </table>\n",
        "                    </div>\n",
        "                </div>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x164fc4588>"
       ]
      }
     ],
     "prompt_number": 398
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fix scraping errors, and define some simple calculations over our data to get the results:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyxdameraulevenshtein import damerau_levenshtein_distance as levenshtein_distance\n",
      "from operator import itemgetter\n",
      "from utils import get_database\n",
      "from numpy.linalg import LinAlgError\n",
      "from collections import Counter\n",
      "import gzip, pickle, re\n",
      "\n",
      "def get_doc2index():\n",
      "    file = gzip.open(\"saves/saved_texts.gz\", 'r')\n",
      "    texts, texts_data = pickle.load(file)\n",
      "    file.close()\n",
      "    document2index = {}\n",
      "    cat_rating_price_2index = {}\n",
      "    for k, text in enumerate(texts_data):\n",
      "        given_name = get_database()[\"restaurants\"].find_one({\"_id\": text[\"_id\"]}, {\"given_name\": 1}).get(\"given_name\")\n",
      "        document2index[text[\"_id\"]] = k\n",
      "        document2index[text[\"id\"]] = k\n",
      "        if given_name != None:\n",
      "            document2index[given_name] = k\n",
      "        if cat_rating_price_2index.get((int(text[\"rating\"]), len(text[\"price\"]), \",\".join(text[\"categories\"]))) is None:\n",
      "            cat_rating_price_2index[(int(text[\"rating\"]), len(text[\"price\"]), \",\".join(text[\"categories\"]))] = [k]\n",
      "        else:\n",
      "            cat_rating_price_2index[(int(text[\"rating\"]), len(text[\"price\"]), \",\".join(text[\"categories\"]))].append(k)\n",
      "\n",
      "    # fixes:\n",
      "    document2index[\"The Georgian Restaurant\"] = 4697\n",
      "    document2index[\"Papa Murphy's Take 'N' Bake pizza\"] = 307\n",
      "    document2index[\"The Hi-life\"] = 1774\n",
      "    document2index[\"Popeyes Louisiana Kitchen\"] = 2144\n",
      "    document2index[\"TASTE Restaurant\"] = 5813\n",
      "    document2index[\"Ballet Vietnamese Restaurant\"] = 4845\n",
      "    document2index[\"Dot's Charcuterie and Bistrot\"] = 3539\n",
      "    document2index[\"Shuckers Oyster Bar\"] = 2985\n",
      "    document2index[\"Jersey Mike's Subs\"] = 2399\n",
      "    document2index[\"Elysian Tangletown\"] = 3910\n",
      "    document2index[\"Buca di Beppo Italian Restaurant\"] = 5877\n",
      "    document2index[\"Ugly Mug Caf\u00e9 & Coffee Roasters\"] = 4365\n",
      "    document2index[\"Salty's\"] = 2173\n",
      "    document2index[\"Ti22\"] = 5732\n",
      "\n",
      "    rating_finder = re.compile(\"<span class='rating'>([^<]+)</span>\")\n",
      "    price_finder = re.compile(\"<span class='pricing'>([^<]*)</span>\")\n",
      "    category_finder = re.compile(\"<span class='category'>([^<]+)</span>\")\n",
      "\n",
      "    def get_rating(html):\n",
      "        return len(re.findall(rating_finder, html)[0])\n",
      "\n",
      "    def get_price(html):\n",
      "        return len(re.findall(price_finder, html)[0])\n",
      "\n",
      "    def get_categories(html):\n",
      "        return \",\".join(re.findall(category_finder, html))\n",
      "    \n",
      "    ambiguous = set()\n",
      "    for ex in loaded_example_sets:\n",
      "        for k, name in enumerate(ex.example_names()):\n",
      "            if not name.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\") in document2index:\n",
      "                html = ex.get_examples_html()[k]\n",
      "                rating = get_rating(html)\n",
      "                price = get_price(html)\n",
      "                categories = get_categories(html)\n",
      "                if len(cat_rating_price_2index[(rating, price, categories)]) > 1:\n",
      "                    alternates =[(texts_data[i][\"_id\"].replace(\"-\", \" \"), i) for i in cat_rating_price_2index[(rating, price, categories)]]\n",
      "\n",
      "                    found = False\n",
      "                    for alternate,i in alternates:\n",
      "                        if alternate.lower().find(name.lower()) != -1:\n",
      "                            document2index[name] = i\n",
      "                            found = True\n",
      "\n",
      "                    if not found:\n",
      "                        distances = [(levenshtein_distance(name.lower(), alternate.lower()), alternate, i) for alternate, i in alternates]\n",
      "                        distances.sort(key=itemgetter(0))\n",
      "                        if distances[0][0] < 3:\n",
      "                            document2index[name] = distances[0][2]\n",
      "                        else:\n",
      "                            ambiguous.add(name)\n",
      "                            print(name, distances)\n",
      "                else:\n",
      "                    document2index[name] = cat_rating_price_2index[(rating, price, categories)][0]\n",
      "\n",
      "        for k, name in enumerate(ex.option_names()):\n",
      "            if not name.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\") in document2index:\n",
      "                html = ex.get_options_html()[k]\n",
      "                rating = get_rating(html)\n",
      "                price = get_price(html)\n",
      "                categories = get_categories(html)\n",
      "                if len(cat_rating_price_2index[(rating, price, categories)]) > 1:\n",
      "                    alternates =[(texts_data[i][\"_id\"].replace(\"-\", \" \"), i) for i in cat_rating_price_2index[(rating, price, categories)]]\n",
      "\n",
      "                    found = False\n",
      "                    for alternate,i in alternates:\n",
      "                        if alternate.lower().find(name.lower()) != -1:\n",
      "                            document2index[name] = i\n",
      "                            found = True\n",
      "\n",
      "                    if not found:\n",
      "                        distances = [(levenshtein_distance(name.lower(), alternate.lower()), alternate, i) for alternate, i in alternates]\n",
      "                        distances.sort(key=itemgetter(0))\n",
      "                        if distances[0][0] < 5:\n",
      "                            document2index[name] = distances[0][2]\n",
      "                        else:\n",
      "                            ambiguous.add(name)\n",
      "                            if distances[0][0] > len(name):\n",
      "                                print(name, distances)\n",
      "                else:\n",
      "                    document2index[name] = cat_rating_price_2index[(rating, price, categories)][0]\n",
      "    return document2index\n",
      "\n",
      "def convert_names_to_indices(document2index, names):\n",
      "    return [document2index.get(name.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\"), document2index.get(name.lower(), None)) for name in names]\n",
      "\n",
      "def model_response(document2index, example, obs):\n",
      "    indices = convert_names_to_indices(document2index, example.example_names())\n",
      "    test_indices = convert_names_to_indices(document2index, example.option_names())\n",
      "    intersect = set(indices) & set(test_indices)\n",
      "    if len(intersect) == 0:\n",
      "        try:\n",
      "            result_inds, result_probs = obs.conditional_probabilities(indices, remaining_indices = test_indices, intensity=0.5)\n",
      "            return test_indices[result_probs[:,0].argmax()]\n",
      "        except LinAlgError:\n",
      "            result_inds, result_probs = obs.conditional_probabilities(indices, remaining_indices = test_indices, singular=True, intensity=0.5)\n",
      "            return test_indices[result_probs[:,0].argmax()]\n",
      "    else:\n",
      "        return intersect\n",
      "    \n",
      "def double_model_response(document2index, example, obs1, obs2, w1=1., w2=1., combine_sum=True):\n",
      "    indices = convert_names_to_indices(document2index, example.example_names())\n",
      "    test_indices = convert_names_to_indices(document2index, example.option_names())\n",
      "    intersect = set(indices) & set(test_indices)\n",
      "    if len(intersect) == 0:\n",
      "        try:\n",
      "            result_inds, result_probs = obs1.conditional_probabilities(indices, remaining_indices = test_indices, intensity=0.5)\n",
      "            result_inds, result_probs2 = obs2.conditional_probabilities(indices, remaining_indices = test_indices, intensity=0.5)\n",
      "            if combine_sum:\n",
      "                return test_indices[(result_probs[:,0] * w1 + result_probs2[:,0] * w2).argmax()]\n",
      "            else:\n",
      "                return test_indices[(np.fmax(result_probs[:,0], result_probs2[:,0])).argmax()]\n",
      "        except LinAlgError:\n",
      "            result_inds, result_probs = obs1.conditional_probabilities(indices, remaining_indices = test_indices, singular=True, intensity=0.5)\n",
      "            result_inds, result_probs2 = obs2.conditional_probabilities(indices, remaining_indices = test_indices,  singular=True, intensity=0.5)\n",
      "            if combine_sum:\n",
      "                return test_indices[(result_probs[:,0] * w1 + result_probs2[:,0] * w2).argmax()]\n",
      "            else:\n",
      "                return test_indices[(np.fmax(result_probs[:,0], result_probs2[:,0])).argmax()]\n",
      "    else:\n",
      "        return intersect\n",
      "    \n",
      "def rule_response(document2index, example):\n",
      "    indices = convert_names_to_indices(document2index, example.example_names())\n",
      "    test_indices = convert_names_to_indices(document2index, example.option_names())\n",
      "    intersect = set(indices) & set(test_indices)\n",
      "    if len(intersect) == 0:\n",
      "        return test_indices[ex_2_rank(example.options)]\n",
      "    else:\n",
      "        return intersect\n",
      "    \n",
      "def rule_response_value(document2index, example):\n",
      "    indices = convert_names_to_indices(document2index, example.example_names())\n",
      "    test_indices = convert_names_to_indices(document2index, example.option_names())\n",
      "    intersect = set(indices) & set(test_indices)\n",
      "    if len(intersect) == 0:\n",
      "        return test_indices[ex_2_value(example.options)]\n",
      "    else:\n",
      "        return intersect\n",
      "    \n",
      "def rule_response_flavor(document2index, example):\n",
      "    indices = convert_names_to_indices(document2index, example.example_names())\n",
      "    test_indices = convert_names_to_indices(document2index, example.option_names())\n",
      "    intersect = set(indices) & set(test_indices)\n",
      "    if len(intersect) == 0:\n",
      "        return test_indices[ex_2_rank_flavor(example.examples, example.options)]\n",
      "    else:\n",
      "        return intersect\n",
      "    \n",
      "def model_response_plural(document2index, example, observer = None):\n",
      "    indices = convert_names_to_indices(document2index, example.example_names())\n",
      "    test_indices = convert_names_to_indices(document2index, example.option_names())\n",
      "    intersect = set(indices) & set(test_indices)\n",
      "    arr = np.array([0., 0., 0.])\n",
      "    if len(intersect) == 0:\n",
      "        try:\n",
      "            result_inds, result_probs = observer.conditional_probabilities(indices, remaining_indices = test_indices, intensity=30.)\n",
      "            return result_probs[:,0]\n",
      "        except LinAlgError:\n",
      "            result_inds, result_probs = observer.conditional_probabilities(indices, remaining_indices = test_indices, singular=True, intensity=30.)\n",
      "            return result_probs[:,0]\n",
      "    else:\n",
      "        arr[test_indices.index(list(intersect)[0])] = 1.0\n",
      "        return arr\n",
      "    \n",
      "def most_common_amount(document2index, ex, response, index):\n",
      "    if index < 4:\n",
      "        common_name = Counter(resp[\"recommendation\"].split(\" \")[0] for resp in response).most_common(2)\n",
      "    else:\n",
      "        common_name = Counter(resp[\"recommendation\"] for resp in response).most_common(2)\n",
      "    \n",
      "    return common_name[0][1]\n",
      "\n",
      "def resp_to_common_index(document2index, ex, response, index):\n",
      "    if index < 4:\n",
      "        common_name = Counter(resp[\"recommendation\"].split(\" \")[0] for resp in response).most_common(2)\n",
      "    else:\n",
      "        common_name = Counter(resp[\"recommendation\"] for resp in response).most_common(2)\n",
      "    \n",
      "    if index < 4:\n",
      "        actual_names = [name.split(\" \")[0] for name in ex.option_names()]\n",
      "        actual_index = actual_names.index(common_name[0][0])\n",
      "        common_name = ex.option_names()[actual_index]\n",
      "    else:\n",
      "        common_name = common_name[0][0]\n",
      "    \n",
      "    return document2index.get(common_name.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\"), document2index.get(common_name.lower(), None))\n",
      "\n",
      "def agreement(response, index):\n",
      "    recommendations = Counter(result[\"recommendation\"] for result in response)\n",
      "    \n",
      "    if index < 4:\n",
      "        recommendations = Counter(result[\"recommendation\"].split(\" \")[0] for result in response)\n",
      "    \n",
      "    num_responses = sum(reco[1] for reco in recommendations.most_common())\n",
      "    return recommendations.most_common(1)[0][1]\n",
      "\n",
      "def agrees_with_human(document2index, model_response, ex, response, index, cutoff):\n",
      "    if index < 4:\n",
      "        recommendations = Counter(result[\"recommendation\"].split(\" \")[0] for result in response)\n",
      "        actual_names = [name.split(\" \")[0] for name in ex.option_names()]\n",
      "        for fake_key, count in recommendations.most_common():\n",
      "            actual_index = actual_names.index(fake_key)\n",
      "            key = ex.option_names()[actual_index]\n",
      "            if count < cutoff:\n",
      "                return 0\n",
      "            key_index = document2index.get(key.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\"), document2index.get(key.lower(), None))\n",
      "            if model_response == key_index:\n",
      "                return 1\n",
      "        return 0\n",
      "        \n",
      "    else:\n",
      "        recommendations = Counter(result[\"recommendation\"] for result in response)\n",
      "        for key, count in recommendations.most_common():\n",
      "            if count < cutoff:\n",
      "                return 0\n",
      "            key_index = document2index.get(key.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\"), document2index.get(key.lower(), None))\n",
      "            if model_response == key_index:\n",
      "                return 1\n",
      "            \n",
      "        return 0\n",
      "    \n",
      "def index_ranks(document2index, ex, response, index):\n",
      "    \n",
      "    if index < 4:\n",
      "        common_name = Counter(resp[\"recommendation\"].split(\" \")[0] for resp in response)\n",
      "    else:\n",
      "        common_name = Counter(resp[\"recommendation\"] for resp in response)\n",
      "        \n",
      "        \n",
      "    \n",
      "    if index < 4:\n",
      "        actual_names = [name.split(\" \")[0] for name in ex.option_names()]\n",
      "    else:\n",
      "        actual_names = ex.option_names()\n",
      "        \n",
      "    arr = np.array([0., 0., 0.])\n",
      "    \n",
      "    for k, name in enumerate(actual_names):\n",
      "        arr[k] = common_name[name]\n",
      "    \n",
      "    return arr\n",
      "\n",
      "def distance_to_next_most_popular(response, index):\n",
      "    recommendations = Counter(result[\"recommendation\"] for result in response)\n",
      "    \n",
      "    if index < 4:\n",
      "        recommendations = Counter(result[\"recommendation\"].split(\" \")[0] for result in response)\n",
      "    \n",
      "    if len(recommendations) > 1:\n",
      "        return recommendations.most_common(2)[0][1] - recommendations.most_common(2)[1][1]\n",
      "    else:\n",
      "        return recommendations.most_common(1)[0][1]\n",
      "\n",
      "def compare_model_responses(document2index, system_responses, human_responses, example_sets, personalities):\n",
      "    agrees_with_many_humans = np.array([agrees_with_human(document2index, model_resp,example_sets[k],human_responses[k],k,3) for k, model_resp in enumerate(system_responses)])\n",
      "    agrees_with_some_humans = np.array([agrees_with_human(document2index, model_resp,example_sets[k],human_responses[k],k,2) for k, model_resp in enumerate(system_responses)])\n",
      "    agrees_with_a_humans    = np.array([agrees_with_human(document2index, model_resp,example_sets[k],human_responses[k],k,1) for k, model_resp in enumerate(system_responses)])\n",
      "\n",
      "    results = []\n",
      "\n",
      "    result_row = [\n",
      "        100 * agrees_with_many_humans.sum() / len(agrees_with_many_humans),\n",
      "        100 * agrees_with_some_humans.sum() / len(agrees_with_some_humans),\n",
      "        100 * agrees_with_a_humans.sum()    / len(agrees_with_a_humans)\n",
      "    ]\n",
      "\n",
      "    results.append(result_row)\n",
      "\n",
      "\n",
      "    for i, p_type in enumerate([\"Price\", \"Cuisine\", \"Rating\", \"Value\"]):\n",
      "        matches = np.where(personalities == i)[0]\n",
      "        result_row = [\n",
      "        100 * agrees_with_many_humans[matches].sum() / len(matches),\n",
      "        100 * agrees_with_some_humans[matches].sum() / len(matches),\n",
      "        100 * agrees_with_a_humans[matches].sum()    / len(matches)\n",
      "                    ]\n",
      "        results.append(result_row)\n",
      "\n",
      "    agreement_types = [\">2 subjects\", \">1 subjects\", \">0 subjects\"]\n",
      "\n",
      "    lines = []\n",
      "    latex_lines = []\n",
      "\n",
      "    latex_lines.append(\" & \".join([\"\\# agree w/. model\", \"Overall\", \"Price\", \"Cuisine\", \"Rating\", \"Value\"]) + \" \\\\\\\\\")\n",
      "    lines.append([\"# agree w/. model\", \"Overall\", \"Price\", \"Cuisine\", \"Rating\", \"Value\"])\n",
      "    latex_lines.append(\"\\hline\")\n",
      "    for k, agreement_type in enumerate(agreement_types):\n",
      "        line = [\"%s \" % (agreement_type)]\n",
      "        line += [\"%.1f\\%%\"% (results[j][k]) for j in range(len(results))]\n",
      "        latex_lines.append(\" & \".join(line) +  \" \\\\\\\\\")\n",
      "        line = [\"%s \" % (agreement_type)] + [\"%.2f%%\"% (results[j][k]) for j in range(len(results))]\n",
      "        lines.append(line)\n",
      "        \n",
      "    return (lines, latex_lines)\n",
      "from IPython.display import display, HTML\n",
      "def show_table(lines):\n",
      "    display(\n",
      "        HTML(\n",
      "            \"\"\"<div class='row'>\n",
      "                    <div class='span7'>\n",
      "                        <table class='table table-bordered'>\n",
      "                            <tbody>\n",
      "                                <tr>\n",
      "                                    <th>\"\"\" + \\\n",
      "                                    \"</th><th>\".join(lines[0]) + \"</th></tr>\" + \\\n",
      "                                    \"</tr>\\n<tr>\".join(\n",
      "                                        [\"<td>\" + \"</td><td>\".join(line) + \"</td>\" for line in lines[1:]]\n",
      "                                    ) + \"\"\"\n",
      "                                </tr>\n",
      "                            </tbody>\n",
      "                        </table>\n",
      "                    </div>\n",
      "                </div>\"\"\"))\n",
      "    \n",
      "def index_ranks(document2index, ex, response, index):\n",
      "    \n",
      "    if index < 4:\n",
      "        common_name = Counter(resp[\"recommendation\"].split(\" \")[0] for resp in response)\n",
      "    else:\n",
      "        common_name = Counter(resp[\"recommendation\"] for resp in response)\n",
      "        \n",
      "        \n",
      "    \n",
      "    if index < 4:\n",
      "        actual_names = [name.split(\" \")[0] for name in ex.option_names()]\n",
      "    else:\n",
      "        actual_names = ex.option_names()\n",
      "        \n",
      "    arr = np.array([0., 0., 0.])\n",
      "    \n",
      "    for k, name in enumerate(actual_names):\n",
      "        arr[k] = common_name[name]\n",
      "    \n",
      "    return arr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "system_scores_lin = np.array([model_response_plural(document2index, ex, observer=observables) for ex in loaded_example_sets])\n",
      "system_scores = np.array([model_response_plural(document2index, ex, observer=observables_bilinear) for ex in loaded_example_sets])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "human_ranks = np.array([index_ranks(document2index,loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])\n",
      "system_scores = np.array([model_response_plural(document2index, ex) for ex in loaded_example_sets])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scipy.stats.kendalltau(human_ranks, system_scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 135,
       "text": [
        "(0.12134743117191801, 0.0011189546053901223)"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scipy.stats.kendalltau(human_ranks, system_scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 136,
       "text": [
        "(0.1175283928105384, 0.0015983243790323853)"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kendall_taus_lin = np.array([list(scipy.stats.kendalltau(human_ranks[i], system_scores_lin[i])) for i in range(len(human_ranks))])\n",
      "kendall_taus_lin[:,0].mean(), kendall_taus_lin[:,1].mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 131,
       "text": [
        "(0.18501354065004619, 0.437865190063008)"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kendall_taus_lin[:,0].mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 132,
       "text": [
        "0.18501354065004619"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kendall_taus_lin[:,1].mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 133,
       "text": [
        "0.437865190063008"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def kendalltau(x, y, initial_lexsort=True):\n",
      "    \"\"\"\n",
      "    Calculates Kendall's tau, a correlation measure for ordinal data.\n",
      "    Kendall's tau is a measure of the correspondence between two rankings.\n",
      "    Values close to 1 indicate strong agreement, values close to -1 indicate\n",
      "    strong disagreement.  This is the tau-b version of Kendall's tau which\n",
      "    accounts for ties.\n",
      "    Parameters\n",
      "    ----------\n",
      "    x, y : array_like\n",
      "        Arrays of rankings, of the same shape. If arrays are not 1-D, they will\n",
      "        be flattened to 1-D.\n",
      "    initial_lexsort : bool, optional\n",
      "        Whether to use lexsort or quicksort as the sorting method for the\n",
      "        initial sort of the inputs. Default is lexsort (True), for which\n",
      "        `kendalltau` is of complexity O(n log(n)). If False, the complexity is\n",
      "        O(n^2), but with a smaller pre-factor (so quicksort may be faster for\n",
      "        small arrays).\n",
      "    Returns\n",
      "    -------\n",
      "    Kendall's tau : float\n",
      "       The tau statistic.\n",
      "    p-value : float\n",
      "       The two-sided p-value for a hypothesis test whose null hypothesis is\n",
      "       an absence of association, tau = 0.\n",
      "    Notes\n",
      "    -----\n",
      "    The definition of Kendall's tau that is used is::\n",
      "      tau = (P - Q) / sqrt((P + Q + T) * (P + Q + U))\n",
      "    where P is the number of concordant pairs, Q the number of discordant\n",
      "    pairs, T the number of ties only in `x`, and U the number of ties only in\n",
      "    `y`.  If a tie occurs for the same pair in both `x` and `y`, it is not\n",
      "    added to either T or U.\n",
      "    References\n",
      "    ----------\n",
      "    W.R. Knight, \"A Computer Method for Calculating Kendall's Tau with\n",
      "    Ungrouped Data\", Journal of the American Statistical Association, Vol. 61,\n",
      "    No. 314, Part 1, pp. 436-439, 1966.\n",
      "    Examples\n",
      "    --------\n",
      "    >>> x1 = [12, 2, 1, 12, 2]\n",
      "    >>> x2 = [1, 4, 7, 1, 0]\n",
      "    >>> tau, p_value = sp.stats.kendalltau(x1, x2)\n",
      "    >>> tau\n",
      "    -0.47140452079103173\n",
      "    >>> p_value\n",
      "    0.24821309157521476\n",
      "    \"\"\"\n",
      "\n",
      "    x = np.asarray(x).ravel()\n",
      "    y = np.asarray(y).ravel()\n",
      "    n = np.int64(len(x))\n",
      "    temp = list(range(n))  # support structure used by mergesort\n",
      "    # this closure recursively sorts sections of perm[] by comparing\n",
      "    # elements of y[perm[]] using temp[] as support\n",
      "    # returns the number of swaps required by an equivalent bubble sort\n",
      "\n",
      "    def mergesort(offs, length):\n",
      "        exchcnt = 0\n",
      "        if length == 1:\n",
      "            return 0\n",
      "        if length == 2:\n",
      "            if y[perm[offs]] <= y[perm[offs+1]]:\n",
      "                return 0\n",
      "            t = perm[offs]\n",
      "            perm[offs] = perm[offs+1]\n",
      "            perm[offs+1] = t\n",
      "            return 1\n",
      "        length0 = length // 2\n",
      "        length1 = length - length0\n",
      "        middle = offs + length0\n",
      "        exchcnt += mergesort(offs, length0)\n",
      "        exchcnt += mergesort(middle, length1)\n",
      "        if y[perm[middle - 1]] < y[perm[middle]]:\n",
      "            return exchcnt\n",
      "        # merging\n",
      "        i = j = k = 0\n",
      "        while j < length0 or k < length1:\n",
      "            if k >= length1 or (j < length0 and y[perm[offs + j]] <=\n",
      "                                                y[perm[middle + k]]):\n",
      "                temp[i] = perm[offs + j]\n",
      "                d = i - j\n",
      "                j += 1\n",
      "            else:\n",
      "                temp[i] = perm[middle + k]\n",
      "                d = (offs + i) - (middle + k)\n",
      "                k += 1\n",
      "            if d > 0:\n",
      "                exchcnt += d\n",
      "            i += 1\n",
      "        perm[offs:offs+length] = temp[0:length]\n",
      "        return exchcnt\n",
      "\n",
      "    # initial sort on values of x and, if tied, on values of y\n",
      "    if initial_lexsort:\n",
      "        # sort implemented as mergesort, worst case: O(n log(n))\n",
      "        perm = np.lexsort((y, x))\n",
      "    else:\n",
      "        # sort implemented as quicksort, 30% faster but with worst case: O(n^2)\n",
      "        perm = list(range(n))\n",
      "        perm.sort(key=lambda a: (x[a], y[a]))\n",
      "\n",
      "    # compute joint ties\n",
      "    first = 0\n",
      "    t = 0\n",
      "    for i in range(1, n):\n",
      "        if x[perm[first]] != x[perm[i]] or y[perm[first]] != y[perm[i]]:\n",
      "            t += ((i - first) * (i - first - 1)) // 2\n",
      "            first = i\n",
      "    t += ((n - first) * (n - first - 1)) // 2\n",
      "\n",
      "    # compute ties in x\n",
      "    first = 0\n",
      "    u = 0\n",
      "    for i in range(1,n):\n",
      "        if x[perm[first]] != x[perm[i]]:\n",
      "            u += ((i - first) * (i - first - 1)) // 2\n",
      "            first = i\n",
      "    u += ((n - first) * (n - first - 1)) // 2\n",
      "\n",
      "    # count exchanges\n",
      "    exchanges = mergesort(0, n)\n",
      "    # compute ties in y after mergesort with counting\n",
      "    first = 0\n",
      "    v = 0\n",
      "    for i in range(1,n):\n",
      "        if y[perm[first]] != y[perm[i]]:\n",
      "            v += ((i - first) * (i - first - 1)) // 2\n",
      "            first = i\n",
      "    v += ((n - first) * (n - first - 1)) // 2\n",
      "    \n",
      "    tot = (n * (n - 1)) // 2\n",
      "\n",
      "    \n",
      "    return [(tot - (v + u - t)), 2.0 * exchanges, u, v]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kendall_taus = np.array([kendalltau(human_ranks[i], system_scores[i]) for i in range(len(human_ranks))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(system_scores + system_scores_lin).argmax(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scipy.stats.kendalltau(human_ranks, system_scores + system_scores_lin)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 142,
       "text": [
        "(0.14675491663890308, 8.1113016896733505e-05)"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kendall_taus_lin = np.array([kendalltau(human_ranks[i], system_scores_lin[i]) for i in range(len(human_ranks))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P, Q, Us, Vs, = kendall_taus_lin.sum(axis=0)\n",
      "n = len(human_ranks)\n",
      "tot = (n * (n-1)) // 2\n",
      "tau = (P - Q) / np.sqrt((tot - Us) * (tot - Vs))\n",
      "svar = (4.0 * n + 10.0) / (9.0 * n * (n - 1))\n",
      "z = tau / np.sqrt(svar)\n",
      "prob = scipy.special.erfc(np.abs(z) / 1.4142136)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tau"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 127,
       "text": [
        "0.0095611471248479348"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tau"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "0.012690249820252714"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "z"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "0.19466328965402757"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "0.8456565567396177"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ex_2_rank(examples):\n",
      "    vals = np.array([len(ex[\"rating\"]) + len(ex[\"price\"]) for ex in examples])\n",
      "    return vals.argmax()\n",
      "\n",
      "def ex_2_value(examples):\n",
      "    vals = np.array([len(ex[\"rating\"]) - len(ex[\"price\"]) for ex in examples])\n",
      "    return vals.argmax()\n",
      "\n",
      "def ex_2_rank_flavor(examples, options):\n",
      "    max_tie = 0\n",
      "    max_tie_num = 0\n",
      "    for ex in examples:\n",
      "        for i, option in enumerate(options):\n",
      "            overlap = len(set(option[\"categories\"]) & set(ex[\"categories\"]))\n",
      "            if overlap > max_tie_num:\n",
      "                max_tie_num = overlap\n",
      "                max_tie = i\n",
      "                \n",
      "    return i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}