{
 "metadata": {
  "name": "",
  "signature": "sha256:1d3f5dd7c600c7849fbd77897e3c25a87ed19e56827e3ee5bace8fd8b7f1d45e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext cythonmagic\n",
      "%load_ext autoreload\n",
      "%matplotlib inline\n",
      "%autoreload 2\n",
      "import numpy as np, os, sys, gzip, pickle, re\n",
      "import matplotlib.pyplot as plt\n",
      "%config InlineBackend.figure_format = 'png'\n",
      "from collections import OrderedDict, Counter\n",
      "from word2vec_extended import Word2VecExtended\n",
      "from IPython.display import clear_output\n",
      "from utils import present_restaurant, get_adjacency_matrix, get_degree_matrix, assign_parents, get_database\n",
      "from IPython.display import display, HTML\n",
      "from IPython.html.widgets import interact, fixed, IntSliderWidget\n",
      "from scipy.cluster.hierarchy import linkage, to_tree, dendrogram\n",
      "from tsne import bh_sne\n",
      "sys.path.append(\"/Users/jonathanraiman/Desktop/Coding/language_modeling/\")\n",
      "from objectlm import ObjectLM, CategoriesConverter, DatasetGenerator, HierarchicalObservation\n",
      "lmsenti = Word2VecExtended.load(\"/Users/jonathanraiman/Desktop/Coding/language_modeling/saves/kid_model_30_oov_senti\")\n",
      "\n",
      "from personality import Personality, CuisinePersonality, ExampleSet, create_mtc_question, load_example_sets, save_example_sets, collect_hit_responses\n",
      "from boto.mturk.connection import MTurkConnection\n",
      "import os, numpy as np, matplotlib.pyplot as plt\n",
      "from IPython.display import display, HTML\n",
      "\n",
      "mtc = MTurkConnection(aws_access_key_id=os.environ['AWS_PENG_ID'],\n",
      "                      aws_secret_access_key=os.environ['AWS_PENG_SECRET'],\n",
      "                      host=\"mechanicalturk.amazonaws.com\")\n",
      "mtc_b = MTurkConnection(aws_access_key_id=os.environ['AWS_ID'],\n",
      "                      aws_secret_access_key=os.environ['AWS_SECRET'],\n",
      "                      host=\"mechanicalturk.amazonaws.com\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The cythonmagic extension is already loaded. To reload it, use:\n",
        "  %reload_ext cythonmagic\n",
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load saved model, covariance matrix, and mechanical turk data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file = gzip.open(\"saves/saved_texts.gz\", 'r')\n",
      "texts, texts_data = pickle.load(file)\n",
      "file.close()\n",
      "categories = set()\n",
      "for el in texts_data:\n",
      "    for c in el[\"categories\"]:\n",
      "        categories.add(c)\n",
      "catconvert = CategoriesConverter(categories)\n",
      "dataset_gen = DatasetGenerator(texts, texts_data, catconvert)\n",
      "\n",
      "# should modify this to do some auto-encoding / self regression.\n",
      "model = ObjectLM(\n",
      "    vocabulary = lmsenti,\n",
      "    object_vocabulary_size = len(texts),\n",
      "    window = 10,\n",
      "    bilinear_form = False,\n",
      "    size = 20,\n",
      "    object_size = 20,\n",
      "    output_sigmoid_classes = catconvert.num_categories,\n",
      "    output_sigmoid_labels = catconvert.index2category,\n",
      "    output_labels = [[\"\", \"$\", \"$$\", \"$$$\", \"$$$$\"], [\"1\", \"2\", \"3\", \"4\", \"5\"]],\n",
      "    output_classes=[5, 5] # \"\", \"$\", \"$$\",...,\"$$$$\", 5 price classes, and 5 rating classes\n",
      ")\n",
      "model.load_saved_weights(\"saves/objectlm_window_10_lm_20_objlm_20_4/\")\n",
      "model.create_normalized_matrices()\n",
      "\n",
      "\n",
      "if os.path.exists(\"saves/__linkage_average.npy\"):\n",
      "    Z = np.load(\"saves/__linkage_average.npy\")\n",
      "else:\n",
      "    y = model.object_matrix.get_value(borrow=True)\n",
      "    Z = linkage(y, method='average', metric='cosine')\n",
      "    np.save(\"saves/__linkage_average.npy\", Z)\n",
      "    \n",
      "    \n",
      "if os.path.exists(\"saves/__covariance__.npy\"):\n",
      "    Cov = np.load(\"saves/__covariance__.npy\")\n",
      "    observables = HierarchicalObservation(Cov)\n",
      "else:\n",
      "    root, nodes = to_tree(Z, rd=True)\n",
      "    assign_parents(root)\n",
      "    adj_mat = get_adjacency_matrix(nodes_small)\n",
      "    deg_mat = get_degree_matrix(nodes_small)\n",
      "    sigma = 5\n",
      "    laplacian = np.diag(deg_mat) - adj_mat + 1/(sigma**2) * np.eye(len(deg_mat))\n",
      "    Cov = np.linalg.inv(laplacian)\n",
      "    np.save(\"saves/__covariance__.npy\", Cov)\n",
      "    observables = HierarchicalObservation(Cov)\n",
      "    \n",
      "    \n",
      "from pyxdameraulevenshtein import damerau_levenshtein_distance as levenshtein_distance\n",
      "\n",
      "def search_for_object(self, object_index, topn = 10, metric = 'cosine'):\n",
      "    present_restaurant(texts_data[object_index], text = texts[object_index])\n",
      "    display(HTML(\"<small>%d</small>\" % object_index))\n",
      "    \n",
      "    print(object_index)\n",
      "    \n",
      "    results = self.most_similar_object(object_index, topn=topn, metric = metric)\n",
      "    if metric == 'euclidean':\n",
      "        max_distance = max(result[1] for result in results)\n",
      "    else:\n",
      "        max_distance = 1\n",
      "    \n",
      "    for result, distance in results:\n",
      "        present_restaurant(texts_data[result], text = texts[result])\n",
      "        display(HTML(\"<small>%d</small>\" % result))\n",
      "        display(HTML(\"\"\"\n",
      "            <div>\n",
      "                <div style='background: rgb(221,222,223);width:102px;padding:1px;border-radius:2px'>\n",
      "                    <div style='height:20px; width:%dpx;padding-left:3px;background-color:rgb(71, 189, 249);font-size:9px;color:white'>\n",
      "                        %.0f%%\n",
      "                    </div>\n",
      "                </div>\n",
      "            </div>\n",
      "            \"\"\" % (int(distance * 100 / max_distance), distance * 100 / max_distance)))\n",
      "   \n",
      "INDEX_SET = set(range(0,model.object_vocabulary_size))\n",
      "\n",
      "def show_conditional_probs(query=\"thai\", topn=20, testn=2):\n",
      "    min_distance_word, min_distance_index, min_distance = nearest_name(query)\n",
      "    test_indices = [min_distance_index] + [i[0] for i in model.most_similar_object(min_distance_index)][:testn-1]\n",
      "    result_inds, result_probs = observables.conditional_probabilities(test_indices, remaining_indices = list(INDEX_SET - set(test_indices)))\n",
      "\n",
      "    top_results = np.argsort(result_probs[:,0])[::-1][:topn]\n",
      "\n",
      "    for i in range(topn):\n",
      "        present_restaurant(texts_data[result_inds[top_results[i]]], text=texts[result_inds[top_results[i]]])\n",
      "        print(result_probs[top_results[i],0])\n",
      "        \n",
      "def show_conditional_probs_from_index(indices, topn=20):\n",
      "    result_inds, result_probs = observables.conditional_probabilities(indices, remaining_indices = list(INDEX_SET - set(indices)))\n",
      "\n",
      "    top_results = np.argsort(result_probs[:,0])[::-1][:topn]\n",
      "\n",
      "    for i in range(topn):\n",
      "        present_restaurant(texts_data[result_inds[top_results[i]]], text=texts[result_inds[top_results[i]]])\n",
      "        print(result_probs[top_results[i],0])\n",
      "        \n",
      "# Mechanical Turk data:\n",
      "loaded_example_sets = load_example_sets(\"saves/example_sets.pkz\")\n",
      "responses_to_example_sets = [[resp for resp in example.get_responses([mtc, mtc_b]) if resp['RejectionTime'] == None and resp['ApprovalTime'] != None] for example in loaded_example_sets]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fix scraping errors to get the indices for all restaurants:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "document2index = {}\n",
      "cat_rating_price_2index = {}\n",
      "for k, text in enumerate(texts_data):\n",
      "    given_name = get_database()[\"restaurants\"].find_one({\"_id\": text[\"_id\"]}, {\"given_name\": 1}).get(\"given_name\")\n",
      "    document2index[text[\"_id\"]] = k\n",
      "    document2index[text[\"id\"]] = k\n",
      "    if given_name != None:\n",
      "        document2index[given_name] = k\n",
      "    if cat_rating_price_2index.get((int(text[\"rating\"]), len(text[\"price\"]), \",\".join(text[\"categories\"]))) is None:\n",
      "        cat_rating_price_2index[(int(text[\"rating\"]), len(text[\"price\"]), \",\".join(text[\"categories\"]))] = [k]\n",
      "    else:\n",
      "        cat_rating_price_2index[(int(text[\"rating\"]), len(text[\"price\"]), \",\".join(text[\"categories\"]))].append(k)\n",
      "\n",
      "# fixes:\n",
      "document2index[\"The Georgian Restaurant\"] = 4697\n",
      "document2index[\"Papa Murphy's Take 'N' Bake pizza\"] = 307\n",
      "document2index[\"The Hi-life\"] = 1774\n",
      "document2index[\"Popeyes Louisiana Kitchen\"] = 2144\n",
      "document2index[\"TASTE Restaurant\"] = 5813\n",
      "document2index[\"Ballet Vietnamese Restaurant\"] = 4845\n",
      "document2index[\"Dot's Charcuterie and Bistrot\"] = 3539\n",
      "document2index[\"Shuckers Oyster Bar\"] = 2985\n",
      "document2index[\"Jersey Mike's Subs\"] = 2399\n",
      "document2index[\"Elysian Tangletown\"] = 3910\n",
      "document2index[\"Buca di Beppo Italian Restaurant\"] = 5877\n",
      "document2index[\"Ugly Mug Caf\u00e9 & Coffee Roasters\"] = 4365\n",
      "document2index[\"Salty's\"] = 2173\n",
      "document2index[\"Ti22\"] = 5732\n",
      "\n",
      "rating_finder = re.compile(\"<span class='rating'>([^<]+)</span>\")\n",
      "price_finder = re.compile(\"<span class='pricing'>([^<]*)</span>\")\n",
      "category_finder = re.compile(\"<span class='category'>([^<]+)</span>\")\n",
      "\n",
      "def get_rating(html):\n",
      "    return len(re.findall(rating_finder, html)[0])\n",
      "\n",
      "def get_price(html):\n",
      "    return len(re.findall(price_finder, html)[0])\n",
      "\n",
      "def get_categories(html):\n",
      "    return \",\".join(re.findall(category_finder, html))\n",
      "\n",
      "from operator import itemgetter\n",
      "ambiguous = set()\n",
      "for ex in loaded_example_sets:\n",
      "    for k, name in enumerate(ex.example_names()):\n",
      "        if not name.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\") in document2index:\n",
      "            html = ex.get_examples_html()[k]\n",
      "            rating = get_rating(html)\n",
      "            price = get_price(html)\n",
      "            categories = get_categories(html)\n",
      "            if len(cat_rating_price_2index[(rating, price, categories)]) > 1:\n",
      "                alternates =[(texts_data[i][\"_id\"].replace(\"-\", \" \"), i) for i in cat_rating_price_2index[(rating, price, categories)]]\n",
      "                \n",
      "                found = False\n",
      "                for alternate,i in alternates:\n",
      "                    if alternate.lower().find(name.lower()) != -1:\n",
      "                        document2index[name] = i\n",
      "                        found = True\n",
      "                \n",
      "                if not found:\n",
      "                    distances = [(levenshtein_distance(name.lower(), alternate.lower()), alternate, i) for alternate, i in alternates]\n",
      "                    distances.sort(key=itemgetter(0))\n",
      "                    if distances[0][0] < 3:\n",
      "                        document2index[name] = distances[0][2]\n",
      "                    else:\n",
      "                        ambiguous.add(name)\n",
      "                        print(name, distances)\n",
      "            else:\n",
      "                document2index[name] = cat_rating_price_2index[(rating, price, categories)][0]\n",
      "    \n",
      "    for k, name in enumerate(ex.option_names()):\n",
      "        if not name.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\") in document2index:\n",
      "            html = ex.get_options_html()[k]\n",
      "            rating = get_rating(html)\n",
      "            price = get_price(html)\n",
      "            categories = get_categories(html)\n",
      "            if len(cat_rating_price_2index[(rating, price, categories)]) > 1:\n",
      "                alternates =[(texts_data[i][\"_id\"].replace(\"-\", \" \"), i) for i in cat_rating_price_2index[(rating, price, categories)]]\n",
      "                \n",
      "                found = False\n",
      "                for alternate,i in alternates:\n",
      "                    if alternate.lower().find(name.lower()) != -1:\n",
      "                        document2index[name] = i\n",
      "                        found = True\n",
      "                \n",
      "                if not found:\n",
      "                    distances = [(levenshtein_distance(name.lower(), alternate.lower()), alternate, i) for alternate, i in alternates]\n",
      "                    distances.sort(key=itemgetter(0))\n",
      "                    if distances[0][0] < 5:\n",
      "                        document2index[name] = distances[0][2]\n",
      "                    else:\n",
      "                        ambiguous.add(name)\n",
      "                        if distances[0][0] > len(name):\n",
      "                            print(name, distances)\n",
      "            else:\n",
      "                document2index[name] = cat_rating_price_2index[(rating, price, categories)][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convert_names_to_indices(names):\n",
      "    return [document2index.get(name.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\"), document2index.get(name.lower(), None)) for name in names]\n",
      "\n",
      "def model_response(example):\n",
      "    indices = convert_names_to_indices(example.example_names())\n",
      "    test_indices = convert_names_to_indices(example.option_names())\n",
      "    intersect = set(indices) & set(test_indices)\n",
      "    if len(intersect) == 0:\n",
      "        result_inds, result_probs = observables.conditional_probabilities(indices, remaining_indices = test_indices)\n",
      "        return test_indices[result_probs[:,0].argmax()]\n",
      "    else:\n",
      "        return intersect\n",
      "    \n",
      "def model_response_better(example):\n",
      "    indices = convert_names_to_indices(example.example_names())\n",
      "    test_indices = convert_names_to_indices(example.option_names())\n",
      "    intersect = set(indices) & set(test_indices)\n",
      "    if len(intersect) == 0:\n",
      "        result_inds, result_probs = observables.conditional_probabilities_jointly(indices, remaining_indices = test_indices)\n",
      "        return test_indices[result_probs[:,0].argmax()]\n",
      "    else:\n",
      "        return intersect"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 335
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_response(loaded_example_sets[10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 361,
       "text": [
        "2126"
       ]
      }
     ],
     "prompt_number": 361
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_responses = np.array([model_response(ex) for ex in loaded_example_sets])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 356
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def resp_to_common_index(ex, response, index):\n",
      "    \n",
      "    if index < 4:\n",
      "        common_name = Counter(resp[\"recommendation\"].split(\" \")[0] for resp in response).most_common(2)\n",
      "    else:\n",
      "        common_name = Counter(resp[\"recommendation\"] for resp in response).most_common(2)\n",
      "    \n",
      "    if index < 4:\n",
      "        actual_names = [name.split(\" \")[0] for name in ex.option_names()]\n",
      "        actual_index = actual_names.index(common_name[0][0])\n",
      "        common_name = ex.option_names()[actual_index]\n",
      "    else:\n",
      "        common_name = common_name[0][0]\n",
      "    \n",
      "    return document2index.get(common_name.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\"), document2index.get(common_name.lower(), None))\n",
      "\n",
      "def agreement(response, index):\n",
      "    recommendations = Counter(result[\"recommendation\"] for result in response)\n",
      "    \n",
      "    if index < 4:\n",
      "        recommendations = Counter(result[\"recommendation\"].split(\" \")[0] for result in response)\n",
      "    \n",
      "    num_responses = sum(reco[1] for reco in recommendations.most_common())\n",
      "    return recommendations.most_common(1)[0][1]\n",
      "\n",
      "def agrees_with_human(model_response, ex, response, index, cutoff):\n",
      "    if index < 4:\n",
      "        recommendations = Counter(result[\"recommendation\"].split(\" \")[0] for result in response)\n",
      "        actual_names = [name.split(\" \")[0] for name in ex.option_names()]\n",
      "        for fake_key, count in recommendations.most_common():\n",
      "            actual_index = actual_names.index(fake_key)\n",
      "            key = ex.option_names()[actual_index]\n",
      "            if count < cutoff:\n",
      "                return 0\n",
      "            key_index = document2index.get(key.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\"), document2index.get(key.lower(), None))\n",
      "            if model_response == key_index:\n",
      "                return 1\n",
      "        return 0\n",
      "        \n",
      "    else:\n",
      "        recommendations = Counter(result[\"recommendation\"] for result in response)\n",
      "        for key, count in recommendations.most_common():\n",
      "            if count < cutoff:\n",
      "                return 0\n",
      "            key_index = document2index.get(key.replace(\"\u2019\",\"'\").replace(\"\u2018\",\"'\"), document2index.get(key.lower(), None))\n",
      "            if model_response == key_index:\n",
      "                return 1\n",
      "            \n",
      "        return 0\n",
      "    \n",
      "\n",
      "def distance_to_next_most_popular(response, index):\n",
      "    recommendations = Counter(result[\"recommendation\"] for result in response)\n",
      "    \n",
      "    if index < 4:\n",
      "        recommendations = Counter(result[\"recommendation\"].split(\" \")[0] for result in response)\n",
      "    \n",
      "    if len(recommendations) > 1:\n",
      "        return recommendations.most_common(2)[0][1] - recommendations.most_common(2)[1][1]\n",
      "    else:\n",
      "        return recommendations.most_common(1)[0][1]\n",
      "\n",
      "human_common_responses = np.array([resp_to_common_index(loaded_example_sets[k], response, k) for k, response in enumerate(responses_to_example_sets)])\n",
      "personalities = np.array([ex.personality_type for ex in loaded_example_sets])\n",
      "agreement = np.array([agreement(resp, k) for k, resp in enumerate(responses_to_example_sets)])\n",
      "agreement_distance = np.array([distance_to_next_most_popular(resp, k) for k, resp in enumerate(responses_to_example_sets)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 276
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = np.where(personalities == 3)[0]\n",
      "\n",
      "np.sum(model_responses[matches] == human_common_responses[matches]) / len(matches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 204,
       "text": [
        "0.5"
       ]
      }
     ],
     "prompt_number": 204
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = np.where(personalities == 0)[0]\n",
      "\n",
      "np.sum(model_responses[matches] == human_common_responses[matches]) / len(matches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 205,
       "text": [
        "0.41666666666666669"
       ]
      }
     ],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = np.where(personalities == 2)[0]\n",
      "\n",
      "np.sum(model_responses[matches] == human_common_responses[matches]) / len(matches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 206,
       "text": [
        "0.25"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = np.where(personalities == 1)[0]\n",
      "\n",
      "np.sum(model_responses[matches] == human_common_responses[matches]) / len(matches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 207,
       "text": [
        "0.51388888888888884"
       ]
      }
     ],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = np.where(agreement == 5)[0]\n",
      "\n",
      "np.sum(model_responses[matches] == human_common_responses[matches]) / len(matches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 223,
       "text": [
        "0.53846153846153844"
       ]
      }
     ],
     "prompt_number": 223
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = np.where(agreement == 4)[0]\n",
      "\n",
      "np.sum(model_responses[matches] == human_common_responses[matches]) / len(matches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 209,
       "text": [
        "0.56521739130434778"
       ]
      }
     ],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = np.where(agreement >= 4)[0]\n",
      "\n",
      "np.sum(model_responses[matches] == human_common_responses[matches]) / len(matches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 363,
       "text": [
        "0.4731182795698925"
       ]
      }
     ],
     "prompt_number": 363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = np.where(agreement == 3)[0]\n",
      "\n",
      "np.sum(model_responses[matches] == human_common_responses[matches]) / len(matches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 214,
       "text": [
        "0.42105263157894735"
       ]
      }
     ],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = np.where(agreement >= 3)[0]\n",
      "\n",
      "np.sum(model_responses[matches] == human_common_responses[matches]) / len(matches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 368,
       "text": [
        "0.55555555555555558"
       ]
      }
     ],
     "prompt_number": 368
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = np.where(agreement == 2)[0]\n",
      "\n",
      "np.sum(model_responses[matches] == human_common_responses[matches]) / len(matches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 211,
       "text": [
        "0.46666666666666667"
       ]
      }
     ],
     "prompt_number": 211
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = np.where(agreement_distance >= 2)[0]\n",
      "\n",
      "np.sum(model_responses[matches] == human_common_responses[matches]) / len(matches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 233,
       "text": [
        "0.5"
       ]
      }
     ],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(model_responses == human_common_responses) / len(model_responses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 222,
       "text": [
        "0.47222222222222221"
       ]
      }
     ],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(model_responses_better == human_common_responses) / len(model_responses_better)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 343,
       "text": [
        "0.46296296296296297"
       ]
      }
     ],
     "prompt_number": 343
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "agrees_with_many_humans = np.array([agrees_with_human(model_resp,loaded_example_sets[k],responses_to_example_sets[k],k,3) for k, model_resp in enumerate(model_responses)])\n",
      "agrees_with_some_humans = np.array([agrees_with_human(model_resp,loaded_example_sets[k],responses_to_example_sets[k],k,2) for k, model_resp in enumerate(model_responses)])\n",
      "agrees_with_a_humans = np.array([agrees_with_human(model_resp,loaded_example_sets[k],responses_to_example_sets[k],k,1) for k, model_resp in enumerate(model_responses)])\n",
      "\n",
      "results = []\n",
      "\n",
      "result_row = [\n",
      "    100 * agrees_with_many_humans.sum() / len(agrees_with_many_humans),\n",
      "    100 * agrees_with_some_humans.sum() / len(agrees_with_some_humans),\n",
      "    100 * agrees_with_a_humans.sum()    / len(agrees_with_a_humans)\n",
      "]\n",
      "\n",
      "print(\"Agrees with > 2 humans %.5f%%\" % result_row[0])\n",
      "print(\"Agrees with 2+  humans %.5f%%\" % result_row[1])\n",
      "print(\"Agrees with a   human  %.5f%%\" % result_row[2])\n",
      "\n",
      "results.append(result_row)\n",
      "\n",
      "\n",
      "for i, p_type in enumerate([\"Price\", \"Cuisine\", \"Rating\", \"Value\"]):\n",
      "    matches = np.where(personalities == i)[0]\n",
      "    result_row = [\n",
      "    100 * agrees_with_many_humans[matches].sum() / len(matches),\n",
      "    100 * agrees_with_some_humans[matches].sum() / len(matches),\n",
      "    100 * agrees_with_a_humans[matches].sum()    / len(matches)\n",
      "                ]\n",
      "    results.append(result_row)\n",
      "    print(\"With %s:\" % (p_type))\n",
      "    print(\"    Agrees with > 2 humans %.5f%%\" % result_row[0])\n",
      "    print(\"    Agrees with 2+  humans %.5f%%\" % result_row[1])\n",
      "    print(\"    Agrees with a   human  %.5f%%\" % result_row[2])\n",
      "    \n",
      "agreement_types = [\">2 subjects\", \">1 subjects\", \">0 subjects\"]\n",
      "\n",
      "lines = []\n",
      "\n",
      "lines.append(\" & \".join([\"\\# agree w/. model\", \"Overall\", \"Price\", \"Cuisine\", \"Rating\", \"Value\"]) + \" \\\\\\\\\")\n",
      "lines.append(\"\\hline\")\n",
      "for k, agreement_type in enumerate(agreement_types):\n",
      "    line = \"%s \" % (agreement_type)\n",
      "    for j in range(len(results)):\n",
      "        line += \"& %.1f\\%%\" % (results[j][k])\n",
      "    line += \" \\\\\\\\\"\n",
      "    lines.append(line)\n",
      "    \n",
      "print(\"\\n\".join(lines))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Agrees with > 2 humans 40.74074%\n",
        "Agrees with 2+  humans 62.96296%\n",
        "Agrees with a   human  81.48148%\n",
        "With Price:\n",
        "    Agrees with > 2 humans 33.33333%\n",
        "    Agrees with 2+  humans 75.00000%\n",
        "    Agrees with a   human  100.00000%\n",
        "With Cuisine:\n",
        "    Agrees with > 2 humans 43.05556%\n",
        "    Agrees with 2+  humans 61.11111%\n",
        "    Agrees with a   human  80.55556%\n",
        "With Rating:\n",
        "    Agrees with > 2 humans 25.00000%\n",
        "    Agrees with 2+  humans 50.00000%\n",
        "    Agrees with a   human  58.33333%\n",
        "With Value:\n",
        "    Agrees with > 2 humans 50.00000%\n",
        "    Agrees with 2+  humans 75.00000%\n",
        "    Agrees with a   human  91.66667%\n",
        "\\# agree w/. model & Overall & Price & Cuisine & Rating & Value \\\\\n",
        "\\hline\n",
        ">2 subjects & 40.7\\%& 33.3\\%& 43.1\\%& 25.0\\%& 50.0\\% \\\\\n",
        ">1 subjects & 63.0\\%& 75.0\\%& 61.1\\%& 50.0\\%& 75.0\\% \\\\\n",
        ">0 subjects & 81.5\\%& 100.0\\%& 80.6\\%& 58.3\\%& 91.7\\% \\\\\n"
       ]
      }
     ],
     "prompt_number": 316
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 307
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}